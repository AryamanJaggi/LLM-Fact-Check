# LLM-Fact-Check
 Real-World Fact Verification using Machine Learning: A New Benchmark

Effective, automatic fact-verification is essential as online misinformation can have devastating consequences. It is conjectured that current approaches and datasets for automatic fact-verification have limited applicability to the real world, which warrants the consideration of alternative approaches. However, no truly real-world dataset exists that can be used to test these approaches or verify concerns regarding those in use currently. Therefore, in this paper I introduce the first fact-verification dataset extracted directly from real-world dialogue and use it to compare task-specific fact-verification models to general purpose Large-Language Models. I find that Large-Language Models significantly outperform task-specific fact verification models in a real-world setting, affirming previous concerns that these task-specific models cannot be used on real-world data. The code to create the dataset, the code to test the models on the dataset, and the dataset itself are all included in this repository.
