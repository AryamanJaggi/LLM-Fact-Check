{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbz1cDfBTP3h",
        "outputId": "0c3a9608-391b-4314-855f-659ff79847eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files, drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtJhkuvVr8iq",
        "outputId": "2ca9d9bd-c670-4013-d85d-8d31c64945a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx\n",
        "!pip install pandas openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpj6rqacTVNZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from docx import Document\n",
        "import os\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XODqI3VaToUx",
        "outputId": "2e8d52d7-47d5-4d00-cb8e-4c21dedff6ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Case #           Case Name\n",
            "0       1  NC vs Amanda Hayes\n",
            "1       2  NC vs Amanda Hayes\n",
            "2       3  NC vs Amanda Hayes\n",
            "3       4  NC vs Amanda Hayes\n",
            "4       5  NC vs Amanda Hayes\n"
          ]
        }
      ],
      "source": [
        "file_path = \"/content/drive/My Drive/RLTdataset(in use)/Deceptive_Cases.xlsx\"\n",
        "deceptive = pd.read_excel(file_path)\n",
        "print(deceptive.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d5bafyHfuAl",
        "outputId": "087fc948-5801-4fef-b9f3-6bfbe8a3ae0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Case #                Case Name\n",
            "0       3  GA vs Andrea Sneiderman\n",
            "1       4  GA vs Andrea Sneiderman\n",
            "2       5  GA vs Andrea Sneiderman\n",
            "3       6  GA vs Andrea Sneiderman\n",
            "4       7  GA vs Andrea Sneiderman\n"
          ]
        }
      ],
      "source": [
        "file_path = \"/content/drive/My Drive/RLTdataset(in use)/Truthful_Cases.xlsx\"\n",
        "truthful = pd.read_excel(file_path)\n",
        "print(truthful.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ij5vbJircnq"
      },
      "outputs": [],
      "source": [
        "def read_docx_files_in_directory(directory_path):\n",
        "    \"\"\"\n",
        "    Iterates through a specified directory, reads the content of each .docx file,\n",
        "    and stores the filename and content in a dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    directory_path (str): The path to the directory containing the .docx files.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with filenames as keys and file contents as values.\n",
        "    \"\"\"\n",
        "    files_content_dict = {}\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith('.docx'):\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "            try:\n",
        "                doc = Document(file_path)\n",
        "                full_text = []\n",
        "                for para in doc.paragraphs:\n",
        "                    full_text.append(para.text)\n",
        "                # Join all text elements into a single string\n",
        "                dic_index = filename[:-5]\n",
        "                files_content_dict[dic_index] = '\\n'.join(full_text)\n",
        "            except IOError as e:\n",
        "                print(f\"Error reading file {filename}: {e}\")\n",
        "            except Exception as e:\n",
        "                print(f\"An unexpected error occurred with file {filename}: {e}\")\n",
        "    return files_content_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_uPv-9NATbZ"
      },
      "outputs": [],
      "source": [
        "deceptive_texts_path = '/content/drive/My Drive/RLTdataset(in use)/RLT_DeceptiveText'\n",
        "deceptive_texts = read_docx_files_in_directory(deceptive_texts_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX5Z82Y9BNny"
      },
      "outputs": [],
      "source": [
        "truthful_texts_path = '/content/drive/My Drive/RLTdataset(in use)/RLT_TruthfulText'\n",
        "truthful_texts = read_docx_files_in_directory(truthful_texts_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCpngu7-BVe-"
      },
      "outputs": [],
      "source": [
        "case_facts_path = '/content/drive/My Drive/RLTdataset(in use)/RLTCaseFacts'\n",
        "case_facts = read_docx_files_in_directory(case_facts_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQJm9xVbXHEM"
      },
      "outputs": [],
      "source": [
        "def find_row_by_case_number(df, case_number):\n",
        "    #Finds the row in the DataFrame where the specified case number is located.\n",
        "\n",
        "    # Filter the DataFrame for rows where the \"Case #\" column matches the case_number\n",
        "    filtered_df = df[df['Case #'] == case_number]\n",
        "\n",
        "    # Check if the filtered DataFrame is empty (i.e., no match found)\n",
        "    if filtered_df.empty:\n",
        "        print(f\"No row found with Case # {case_number}.\")\n",
        "        return None\n",
        "    else:\n",
        "        # Return the matching row(s)\n",
        "        return filtered_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADT9UUH1ZFvj"
      },
      "source": [
        "#GPT-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFxvl9aJLXT5",
        "outputId": "3f4b5e67-5d86-4478-8d40-d355bf9e53bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/262.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/262.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LeT3QIJoFzI"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u_aABr96S9F"
      },
      "outputs": [],
      "source": [
        "system_spec = '''\n",
        "You are a fact checkers for court cases.\n",
        "Based on the case background, determine if an individual’s answers to questions posed by the attorney/judge are truthful (output “Truthful”), deceptive (output “Deceptive”), or if there is not enough information to decide (output “Indeterminate”). An answer is considered deceptive if any part of the answer is not true. Follow these instructions when analyzing the dialogue:\n",
        "\n",
        "1. Do not analyze what is said by the judge/attorney for factuality. Assume they are incapable of lying.\n",
        "\n",
        "2. Only label answers as truthful or deceptive if your decision is explicitly supported by evidence found in the case background. Otherwise, label the answers as “Indeterminate.”\n",
        "\n",
        "3. Format your answer in JSON format as shown below, with your explanation citing evidence extracted from the case background:\n",
        "\n",
        "\t{\n",
        "\n",
        "`\t  “verdict” : Literal [“Truthful”, “Deceptive”, “Indeterminate”],\n",
        "\t  “explanation” : str\n",
        "\n",
        "  }\n",
        "'''\n",
        "# the above one is depreceated for now\n",
        "system_spec = '''\n",
        "You are a fact checker for court cases.\n",
        "Based on the case background, determine if an individual’s answers to questions posed by the attorney/judge are truthful (output “Truthful”) or deceptive (output “Deceptive”). An answer is considered deceptive if any part of the answer is not true. Follow these instructions when analyzing the dialogue:\n",
        "\n",
        "1. Do not analyze what is said by the judge/attorney for factuality. Assume they are incapable of lying.\n",
        "\n",
        "2. Format your answer in JSON format as shown below, with your explanation citing evidence extracted from the case background:\n",
        "\n",
        "\t{\n",
        "\n",
        "`\t  “verdict” : Literal [“Truthful”, “Deceptive”]\n",
        "\t  “explanation” : str\n",
        "\n",
        "  }\n",
        "'''\n",
        "#use system fingerprint for better understanding\n",
        "def call_gpt(mdl, prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=mdl,\n",
        "        response_format = { \"type\": \"json_object\" }, # get json so it is easy to quickly see what verdict the model gave\n",
        "        temperature = 0, # set low so that is it deterministic. Maybe to 0 (but prob not cus you want 3 dif responses to choose from)\n",
        "        logprobs= True, # retrieve log probability to see how confident model was in each of its 3 responses\n",
        "        top_logprobs = 3, # set to 3 so you can see how likely it was to choose truth, lie, or indeterminate\n",
        "        stop=None,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_spec},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "    )\n",
        "    output = json.loads(response.choices[0].message.content)\n",
        "    return output['verdict'], output['explanation'], response.choices[0].logprobs.content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(system_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHqZCWhhk5FP",
        "outputId": "54c4c457-6fef-45ed-8770-01dad8b6acc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a fact checker for court cases.\n",
            "Based on the case background, determine if an individual’s answers to questions posed by the attorney/judge are truthful (output “Truthful”) or deceptive (output “Deceptive”). An answer is considered deceptive if any part of the answer is not true. Follow these instructions when analyzing the dialogue:\n",
            "\n",
            "1. Do not analyze what is said by the judge/attorney for factuality. Assume they are incapable of lying.\n",
            "\n",
            "2. Format your answer in JSON format as shown below, with your explanation citing evidence extracted from the case background:\n",
            "\n",
            "\t{\n",
            "\n",
            "`\t  “verdict” : Literal [“Truthful”, “Deceptive”]\n",
            "\t  “explanation” : str\n",
            "\n",
            "  }\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYAH-5H4D1mP"
      },
      "outputs": [],
      "source": [
        "def truthful_eval (mdl):\n",
        "  # Define a list of column names\n",
        "  columns = [\"case\", \"verdict\", \"explanation\",\"truth\", \"lie\", \"indeterminate\"]\n",
        "\n",
        "  # Create an empty DataFrame\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  for case_num in truthful_texts: # iterates through dictionary and finds case number for each truthful case\n",
        "\n",
        "    #Goes through Pandas dataframe to find case facts for that specific case\n",
        "    filtered_df = find_row_by_case_number(truthful, int(case_num))\n",
        "    facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "    text = truthful_texts[case_num]\n",
        "    prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "    verdict, explanation, probs = call_gpt(mdl, prompt) # for mdl, we will use gpt-4-0125-preview and gpt-3.5-turbo-0125\n",
        "\n",
        "    for i in probs:\n",
        "      if i.token in \"Indeterminate\" or i.token in \"Deceptive\" or i.token in \"Truthful\":\n",
        "        #Ind means Indeterminate, Truth means Truthful, De means Deceptive\n",
        "        #Gpt will always tokenize them like this so could replace and us == to be more concise\n",
        "        for j in i.top_logprobs:\n",
        "          if (j.token in \"Indeterminate\"):\n",
        "            indeterminate = np.round(np.exp(j.logprob)*100,2)\n",
        "          elif (j.token in \"Deceptive\"):\n",
        "            lie = np.round(np.exp(j.logprob)*100,2)\n",
        "          elif (j.token in \"Truthful\"):\n",
        "            truth = np.round(np.exp(j.logprob)*100,2)\n",
        "        break\n",
        "    df = df.append({\n",
        "      \"case\": int(case_num),  # Random case number\n",
        "      \"verdict\": verdict,\n",
        "      \"explanation\": explanation,\n",
        "      \"truth\": truth,\n",
        "      \"lie\": lie,\n",
        "      \"indeterminate\": indeterminate\n",
        "    }, ignore_index=True)\n",
        "  df = df.sort_values(by='case', ascending=True)\n",
        "  df.to_excel(r'/content/drive/MyDrive/Model_Evals/GPT_3.5_Turbo/truthful.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW9HBqIgu1Zv"
      },
      "outputs": [],
      "source": [
        "def deceptive_eval (mdl):\n",
        "  # Define a list of column names\n",
        "  columns = [\"case\", \"verdict\", \"explanation\",\"truth\", \"lie\", \"indeterminate\"]\n",
        "\n",
        "  # Create an empty DataFrame\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  for case_num in deceptive_texts: # iterates through dictionary and finds case number for each deceptive case\n",
        "\n",
        "    #Goes through Pandas dataframe to find case facts for that specific case\n",
        "    filtered_df = find_row_by_case_number(deceptive, int(case_num))\n",
        "    facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "    text = deceptive_texts[case_num]\n",
        "    prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "    verdict, explanation, probs = call_gpt(mdl, prompt) # for mdl, we will use gpt-4-0125-preview and gpt-3.5-turbo-0125\n",
        "\n",
        "    for i in probs:\n",
        "      if i.token in \"Indeterminate\" or i.token in \"Deceptive\" or i.token in \"Truthful\":\n",
        "        #Ind means Indeterminate, Truth means Truthful, De means Deceptive\n",
        "        #Gpt will always tokenize them like this so could replace and us == to be more concise\n",
        "        for j in i.top_logprobs:\n",
        "          if (j.token in \"Indeterminate\"):\n",
        "            indeterminate = np.round(np.exp(j.logprob)*100,2)\n",
        "          elif (j.token in \"Deceptive\"):\n",
        "            lie = np.round(np.exp(j.logprob)*100,2)\n",
        "          elif (j.token in \"Truthful\"):\n",
        "            truth = np.round(np.exp(j.logprob)*100,2)\n",
        "        break\n",
        "    df = df.append({\n",
        "      \"case\": int(case_num),  # Random case number\n",
        "      \"verdict\": verdict,\n",
        "      \"explanation\": explanation,\n",
        "      \"truth\": truth,\n",
        "      \"lie\": lie,\n",
        "      \"indeterminate\": indeterminate\n",
        "    }, ignore_index=True)\n",
        "  df = df.sort_values(by='case', ascending=True)\n",
        "  df.to_excel(r'/content/drive/MyDrive/Model_Evals/GPT_3.5_Turbo/deceptive.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def truthful_eval (mdl):\n",
        "  # Define a list of column names\n",
        "  columns = [\"case\", \"verdict\", \"explanation\",\"truth\", \"lie\"]\n",
        "\n",
        "  # Create an empty DataFrame\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  for case_num in truthful_texts: # iterates through dictionary and finds case number for each truthful case\n",
        "\n",
        "    #Goes through Pandas dataframe to find case facts for that specific case\n",
        "    filtered_df = find_row_by_case_number(truthful, int(case_num))\n",
        "    facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "    text = truthful_texts[case_num]\n",
        "    prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "    verdict, explanation, probs = call_gpt(mdl, prompt) # for mdl, we will use gpt-4-0125-preview and gpt-3.5-turbo-0125\n",
        "\n",
        "    for i in probs:\n",
        "      if i.token in \"Deceptive\" or i.token in \"Truthful\":\n",
        "        #Ind means Indeterminate, Truth means Truthful, De means Deceptive\n",
        "        #Gpt will always tokenize them like this so could replace and us == to be more concise\n",
        "        for j in i.top_logprobs:\n",
        "          if (j.token in \"Deceptive\"):\n",
        "            lie = np.round(np.exp(j.logprob)*100,2)\n",
        "          elif (j.token in \"Truthful\"):\n",
        "            truth = np.round(np.exp(j.logprob)*100,2)\n",
        "        break\n",
        "    df = df.append({\n",
        "      \"case\": int(case_num),  # Random case number\n",
        "      \"verdict\": verdict,\n",
        "      \"explanation\": explanation,\n",
        "      \"truth\": truth,\n",
        "      \"lie\": lie\n",
        "    }, ignore_index=True)\n",
        "  df = df.sort_values(by='case', ascending=True)\n",
        "  df.to_excel(r'/content/drive/MyDrive/Model_Evals/GPT_4_Turbo/truthful_2choice.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "GeVsxFpWkUlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deceptive_eval (mdl):\n",
        "  # Define a list of column names\n",
        "  columns = [\"case\", \"verdict\", \"explanation\",\"truth\", \"lie\"]\n",
        "\n",
        "  # Create an empty DataFrame\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  for case_num in deceptive_texts: # iterates through dictionary and finds case number for each truthful case\n",
        "\n",
        "    #Goes through Pandas dataframe to find case facts for that specific case\n",
        "    filtered_df = find_row_by_case_number(deceptive, int(case_num))\n",
        "    facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "    text = deceptive_texts[case_num]\n",
        "    prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "    verdict, explanation, probs = call_gpt(mdl, prompt) # for mdl, we will use gpt-4-0125-preview and gpt-3.5-turbo-0125\n",
        "\n",
        "    for i in probs:\n",
        "      if i.token in \"Deceptive\" or i.token in \"Truthful\":\n",
        "        #Ind means Indeterminate, Truth means Truthful, De means Deceptive\n",
        "        #Gpt will always tokenize them like this so could replace and us == to be more concise\n",
        "        for j in i.top_logprobs:\n",
        "          if (j.token in \"Deceptive\"):\n",
        "            lie = np.round(np.exp(j.logprob)*100,2)\n",
        "          elif (j.token in \"Truthful\"):\n",
        "            truth = np.round(np.exp(j.logprob)*100,2)\n",
        "        break\n",
        "    df = df.append({\n",
        "      \"case\": int(case_num),  # Random case number\n",
        "      \"verdict\": verdict,\n",
        "      \"explanation\": explanation,\n",
        "      \"truth\": truth,\n",
        "      \"lie\": lie\n",
        "    }, ignore_index=True)\n",
        "  df = df.sort_values(by='case', ascending=True)\n",
        "  df.to_excel(r'/content/drive/MyDrive/Model_Evals/GPT_4_Turbo/deceptive_2choice.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "YObfTZ-_kpxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsuxE8n1vPge"
      },
      "outputs": [],
      "source": [
        "#truthful_eval(\"gpt-4-0125-preview\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMO_UeEP1cPA"
      },
      "outputs": [],
      "source": [
        "#deceptive_eval(\"gpt-4-0125-preview\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvlaMQVs7FpV"
      },
      "outputs": [],
      "source": [
        "truthful_eval(\"gpt-4-0125-preview\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EPii9OU7SfW",
        "outputId": "f133f71d-b541-4b2f-a252-52c99f3810dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-26-a4d015b4bff9>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n"
          ]
        }
      ],
      "source": [
        "deceptive_eval(\"gpt-4-0125-preview\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3WjL8BaVYM0",
        "outputId": "2e4780e4-5b51-4439-f843-955f11d491d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indeterminate\n",
            "The case background provides detailed information about Jodi Arias, her relationship with Travis Alexander, the circumstances of his murder, and her subsequent arrest and trial. However, it does not provide specific information about her behavior or demeanor during her visit with Ryan Burns in West Jordan, including how she interacted in social settings or one-on-one during that time. Therefore, there is not enough information to determine whether Ryan Burns' observations about Arias' behavior and demeanor are truthful or deceptive.\n"
          ]
        }
      ],
      "source": [
        "#Answer was \"False\"\n",
        "numFakeLie = 0;\n",
        "numRealLie = 0;\n",
        "\n",
        "#Answer was \"True\"\n",
        "numFakeTruth = 0;\n",
        "numRealTruth = 0;\n",
        "\n",
        "#Answer was \"Indeterminate\"\n",
        "numIndeterminate_False = 0; #Actual answer was False\n",
        "numIndeterminate_True = 0; #Actual answer was True\n",
        "\n",
        "#gpt-3.5-turbo-0125\n",
        "#gpt-4-0125-preview\n",
        "\n",
        "verdict, explanation, response = call_gpt(\"gpt-4-0125-preview\", prompt)\n",
        "print(verdict)\n",
        "print(explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BotPBE_X41A9",
        "outputId": "d04aac54-38d8-492f-8a5e-9d3dde1ad34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deceptive\n",
            "Based on the case background, it is established that Jonathan Kendrick's statement that he never molested Candace Conti is deceptive. The case facts clearly outline that Candace Conti testified that Kendrick began molesting her when she was around nine years old and that the incidents occurred multiple times over a couple of years, including during field service activities. Additionally, other witnesses testified to seeing inappropriate behavior between Kendrick and Conti, such as holding hands and Kendrick putting his arm around her. Therefore, Kendrick's denial of ever being alone with Candace Conti and molesting her is contradicted by the evidence presented in the case.\n"
          ]
        }
      ],
      "source": [
        "model = \"gpt-3.5-turbo-0125\"\n",
        "case_num = \"060\"\n",
        "filtered_df = find_row_by_case_number(deceptive, int(case_num))\n",
        "facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "\n",
        "text = deceptive_texts[case_num]\n",
        "prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "verdict, explanation, response = call_gpt(model, prompt) # for mdl, we will use gpt-4-0125-preview and gpt-3.5-turbo-0125\n",
        "\n",
        "print(verdict)\n",
        "print(explanation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6IojVxiZKSL"
      },
      "source": [
        "# Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiVomTl2LJwg",
        "outputId": "900842e2-5090-4b5f-8624-3a351b2caa39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m133.1/137.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJqLpTrxLMlk"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1VvnFLjKIz0"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY= 'AIzaSyCeXqz1BPxLGVtzc5QaEvSI7y4FJw5cT8Y'\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B00um-uoQPfe"
      },
      "outputs": [],
      "source": [
        "configurations = genai.GenerationConfig(temperature=0.0)\n",
        "safe = [\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\",\n",
        "        },\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpoLgC4oLe7j",
        "outputId": "aa7f4bba-442f-4ff0-f274-9884b2280e95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "genai.GenerativeModel(\n",
            "    model_name='models/gemini-1.0-pro',\n",
            "    generation_config={'temperature': 0.0},\n",
            "    safety_settings={<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 10>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HARASSMENT: 7>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HATE_SPEECH: 8>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 9>: <HarmBlockThreshold.BLOCK_NONE: 4>},\n",
            "    tools=None,\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = genai.GenerativeModel('gemini-1.0-pro', safety_settings=safe, generation_config=configurations)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtdlMgyHg7u1"
      },
      "outputs": [],
      "source": [
        "system_spec = '''\n",
        "You are a fact checkers for court cases.\n",
        "Based on the case background, determine if an individual’s answers to questions posed by the attorney/judge are truthful (output “Truthful”), deceptive (output “Deceptive”), or if there is not enough information to decide (output “Indeterminate”). An answer is considered deceptive if any part of the answer is not true. Follow these instructions when analyzing the dialogue:\n",
        "\n",
        "1. Do not analyze what is said by the judge/attorney for factuality. Assume they are incapable of lying.\n",
        "\n",
        "2. Only label answers as truthful or deceptive if your decision is explicitly supported by evidence found in the case background. Otherwise, label the answers as “Indeterminate.”\n",
        "\n",
        "3. Format your answer in JSON format as shown below, with your explanation citing evidence extracted from the case background:\n",
        "\n",
        "\t{\n",
        "\n",
        "`\t  “verdict” : Literal [“Truthful”, “Deceptive”, “Indeterminate”],\n",
        "\t  “explanation” : str\n",
        "\n",
        "  }\n",
        "'''\n",
        "#use system fingerprint for better understanding\n",
        "def call_gem(mdl, prompt):\n",
        "    #creating conversational history since gemini doesn't let you use system insturctions like GPT\n",
        "    messages = [{'role':'user', 'parts': [system_spec]}]\n",
        "    messages.append({'role':'model', 'parts': 'I understand'})\n",
        "\n",
        "    #prompt\n",
        "    messages.append({'role':'user', 'parts': prompt})\n",
        "\n",
        "    #output\n",
        "    response = mdl.generate_content(messages)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "jBUrvEJ_MzRu",
        "outputId": "64efb5db-f03c-4a9f-c520-57406cfcda28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "response:\n",
            "GenerateContentResponse(\n",
            "    done=True,\n",
            "    iterator=None,\n",
            "    result=glm.GenerateContentResponse({'prompt_feedback': {'block_reason': 2, 'safety_ratings': []}, 'candidates': []}),\n",
            "),\n",
            "error=<BlockedPromptException> prompt_feedback {\n",
            "  block_reason: OTHER\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "case_num = \"060\"\n",
        "filtered_df = find_row_by_case_number(deceptive, int(case_num))\n",
        "facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "\n",
        "text = deceptive_texts[case_num]\n",
        "prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "response = call_gem(model, prompt) # for mdl, we will use gpt-4-0125-preview and gpt-3.5-turbo-0125\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yedh7kvCZQ7L"
      },
      "source": [
        "# LlamaV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3ACxlVxsmDz",
        "outputId": "0b5afb7f-92d0-4698-b368-7b20e8f85466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-0.25.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (24.0)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.6.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.10.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (2.16.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.0)\n",
            "Installing collected packages: replicate\n",
            "Successfully installed replicate-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoqYcwmWaKzI"
      },
      "outputs": [],
      "source": [
        "import replicate\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhR_zDcDb_hi"
      },
      "outputs": [],
      "source": [
        "os.environ['REPLICATE_API_TOKEN'] = 'r8_Vq1IaMpCSKhEzd03NC7VhQEdf9rkVUr3D7zqJ'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4jnUTyIz-5p"
      },
      "outputs": [],
      "source": [
        "#meta/llama-2-70b-chat. maybe also the one that is not fine-tuned on chat\n",
        "def run_llama(mdl, prompt, system_spec):\n",
        "  output = replicate.run(\n",
        "      mdl,\n",
        "      input={\n",
        "          \"system_prompt\": system_spec,\n",
        "          \"prompt\": prompt,\n",
        "          \"temperature\": 0.01,\n",
        "          \"repetition_penalty\": 1.0,\n",
        "          \"max_tokens\" : 100 # set for this one but not the others because it is not giving json format so want it to be concise at least so I can manually evaluate it easily\n",
        "      },\n",
        "  )\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ofl-AEG76pl"
      },
      "outputs": [],
      "source": [
        "def truthful_eval_LLama (mdl, system_spec_3choice, system_spec_2choice):\n",
        "  # Define a list of column names\n",
        "  columns = [\"case\", \"3-choice\", \"explanation_3\", \"2-choice\", \"explanation_2\"]\n",
        "\n",
        "  # Create an empty DataFrame\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  for case_num in truthful_texts: # iterates through dictionary and finds case number for each truthful case\n",
        "\n",
        "    #Goes through Pandas dataframe to find case facts for that specific case\n",
        "    filtered_df = find_row_by_case_number(truthful, int(case_num))\n",
        "    facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "    text = truthful_texts[case_num]\n",
        "    prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "    explanation_3 = run_llama(mdl, prompt, system_spec_3choice) # true, false, or indeterminate\n",
        "    explanation_2 = run_llama(mdl, prompt, system_spec_2choice) # true or false\n",
        "    df = df.append({\n",
        "      \"case\": int(case_num),\n",
        "      \"3-choice\": \"empty\",\n",
        "      \"explanation_3\": explanation_3,\n",
        "      \"2-choice\": \"empty\",\n",
        "      \"explanation_2\": explanation_2,\n",
        "    }, ignore_index=True)\n",
        "  df = df.sort_values(by='case', ascending=True)\n",
        "  df.to_excel(r'/content/drive/MyDrive/Model_Evals/Llama_V2_70B_Chat/truthful.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDFPhJtG_uBL"
      },
      "outputs": [],
      "source": [
        "def deceptive_eval_LLama (mdl, system_spec_3choice, system_spec_2choice):\n",
        "  # Define a list of column names\n",
        "  columns = [\"case\", \"3-choice\", \"explanation_3\", \"2-choice\", \"explanation_2\"]\n",
        "\n",
        "  # Create an empty DataFrame\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  for case_num in deceptive_texts: # iterates through dictionary and finds case number for each deceptive case\n",
        "\n",
        "    #Goes through Pandas dataframe to find case facts for that specific case\n",
        "    filtered_df = find_row_by_case_number(deceptive, int(case_num))\n",
        "    facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "    text = deceptive_texts[case_num]\n",
        "    prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "    explanation_3 = run_llama(mdl, prompt, system_spec_3choice) # true, false, or indeterminate\n",
        "    explanation_2 = run_llama(mdl, prompt, system_spec_2choice) # true or false\n",
        "    df = df.append({\n",
        "      \"case\": int(case_num),\n",
        "      \"3-choice\": \"empty\",\n",
        "      \"explanation_3\": explanation_3,\n",
        "      \"2-choice\": \"empty\",\n",
        "      \"explanation_2\": explanation_2,\n",
        "    }, ignore_index=True)\n",
        "  df = df.sort_values(by='case', ascending=True)\n",
        "  df.to_excel(r'/content/drive/MyDrive/Model_Evals/Llama_V2_70B_Chat/deceptive.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diLKhxGj-IWO"
      },
      "outputs": [],
      "source": [
        "system_spec_3choice = '''\n",
        "You are a fact checker for court cases.\n",
        "Based on the case background, determine if an individual’s answers to questions posed by the attorney/judge are truthful (output “Truthful”), deceptive (output “Deceptive”), or if there is not enough information to decide (output “Indeterminate”). An answer is considered deceptive if any part of the answer is not true. Follow these instructions when analyzing the dialogue:\n",
        "\n",
        "1. Do not analyze what is said by the judge/attorney for factuality. Assume they are incapable of lying.\n",
        "\n",
        "2. Only label answers as truthful or deceptive if your decision is explicitly supported by evidence found in the case background. Otherwise, label the answers as “Indeterminate.”\n",
        "\n",
        "3. Format your answer as shown below, with your explanation citing evidence extracted from the case background:\n",
        "\n",
        "\t  “verdict” : Literal [“Truthful”, “Deceptive”, “Indeterminate”]\n",
        "\t  “explanation” : str\n",
        "'''\n",
        "\n",
        "system_spec_2choice = '''\n",
        "You are a fact checker for court cases.\n",
        "Based on the case background, determine if an individual’s answers to questions posed by the attorney/judge are truthful (output “Truthful”) or deceptive (output “Deceptive”). An answer is considered deceptive if any part of the answer is not true. Follow these instructions when analyzing the dialogue:\n",
        "\n",
        "1. Do not analyze what is said by the judge/attorney for factuality. Assume they are incapable of lying.\n",
        "\n",
        "2. Format your answer as shown below, with your explanation citing evidence extracted from the case background:\n",
        "\n",
        "\t  “verdict” : Literal [“Truthful”, “Deceptive”]\n",
        "\t  “explanation” : str\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ3r4N9k-v9k"
      },
      "outputs": [],
      "source": [
        "#truthful_eval_LLama(\"meta/llama-2-70b-chat\", system_spec_3choice, system_spec_2choice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpTb9LBfA_JC",
        "outputId": "960935e0-1559-4370-e1fa-1d9c981fbd40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-17-40fc7f25de36>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n"
          ]
        }
      ],
      "source": [
        "deceptive_eval_LLama(\"meta/llama-2-70b-chat\", system_spec_3choice, system_spec_2choice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neNntsc0eqfj",
        "outputId": "6b02b710-4a05-4ebf-9662-c2e0db4eefff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['This', ' conversation', ' is', ' fact', 'ual', ' in', ' nature', ',', ' as', ' it', ' involves', ' a', ' discussion', ' about', ' Jonathan', ' K', 'end', 'rick', \"'\", 's', ' interactions', ' with', ' Cand', 'ace', ' Cont', 'i', ' and', ' his', ' den', 'ial', ' of', ' any', ' in', 'app', 'ropri', 'ate', ' behavior', '.', ' The', ' conversation', ' is', ' relevant', ' to', ' the', ' legal', ' case', ' involving', ' Cont', 'i', \"'\", 's', ' alleg', 'ations', ' of', ' sexual', ' ab', 'use', ' against', ' K', 'end', 'rick', ' and', ' the', ' defend', 'ants', \"'\", ' response', ' to', ' those', ' alleg', 'ations', '.', '\\n\\nIn', ' this', ' conversation', ',', ' K', 'end', 'rick', ' den', 'ies', ' being', ' alone', ' with', ' Cont', 'i', ' and', ' mol', 'est', 'ing', ' her', '.', ' He', ' also', ' emphas', 'izes', ' that', ' he', ' has', ' never', ' been', ' alone', ' with', ' her', ',', ' ever', '.', ' This', ' statement', ' is', ' important', ' because', ' it', ' suggests', ' that', ' K', 'end', 'rick', ' is', ' ref', 'uting', ' Cont', 'i', \"'\", 's']\n"
          ]
        }
      ],
      "source": [
        "model = \"meta/llama-2-70b-chat\"\n",
        "case_num = \"060\"\n",
        "filtered_df = find_row_by_case_number(deceptive, int(case_num))\n",
        "facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "\n",
        "text = deceptive_texts[case_num]\n",
        "prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "response = run_llama(model, prompt) # for mdl, we will use gpt-4-0125-preview and gpt-3.5-turbo-0125\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0Aod3sbZTh3"
      },
      "source": [
        "#Mistral. Will be testing their best open source model (mistral 8x7B which uses Mixture of Experts) and their best overall model (Mistral Large)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "t1hJgZWbUuky",
        "outputId": "5447ce8f-a3be-44bf-ad17-4a5d26210117"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mistralai\n",
            "  Downloading mistralai-0.1.8-py3-none-any.whl (15 kB)\n",
            "Collecting httpx<0.26.0,>=0.25.2 (from mistralai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.10 (from mistralai)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from mistralai) (2.6.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (1.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.26.0,>=0.25.2->mistralai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (4.10.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.26.0,>=0.25.2->mistralai) (1.2.0)\n",
            "Installing collected packages: orjson, httpx, mistralai\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.27.0\n",
            "    Uninstalling httpx-0.27.0:\n",
            "      Successfully uninstalled httpx-0.27.0\n",
            "Successfully installed httpx-0.25.2 mistralai-0.1.8 orjson-3.9.15\n"
          ]
        }
      ],
      "source": [
        "!pip install mistralai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqoBYeIWVHHD"
      },
      "outputs": [],
      "source": [
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCoK0fZsQ33P"
      },
      "outputs": [],
      "source": [
        "mistral_api_key = 'zmOEqCrIQy1roeM7KfxMoWmMJ72IUvZM'\n",
        "client = MistralClient(api_key=mistral_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZEU3OqbV3Tz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0b530f1-c3f6-4dea-b8c4-a28474631044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id='open-mistral-7b' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-aa43e145a13d478e91c5b1ac83d333c9', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='mistral-tiny-2312' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-26c7dfb5e783452784528a76a108fc38', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='mistral-tiny' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-0854c8010dae4705b34c16149d7a7059', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='open-mixtral-8x7b' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-84be2d12324842de84e6cf596d226fc9', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='mistral-small-2312' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-04c0ae1cca734c268773d80f86176791', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='mistral-small' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-e9ccff99ef5f4a2080b40d81684a7b71', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='mistral-small-2402' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-d876529016974fdf876446a4e6904a85', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='mistral-small-latest' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-ce46f09bb77141229fbf256805cf71c9', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='mistral-medium-latest' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-999a96c3239e479cb712ab06f07d4d87', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='mistral-medium-2312' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-59be844a585546fa898bebc22d16da92', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='mistral-medium' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-ce86e758912f49d890a1e7b65c0ae729', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='mistral-large-latest' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-869b30018db44ea2ad6d953f3353170c', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='mistral-large-2402' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-55c6ab589bb04bc4b2631e8f17fbac78', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n",
            "id='mistral-embed' object='model' created=1711497940 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-e8529440d9514681a86324475c448e37', object='model_permission', created=1711497940, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# mistral-large-latest\n",
        "# open-mixtral-8x7b\n",
        "list_models_response = client.list_models()\n",
        "for model in list_models_response.data:\n",
        "  print(model)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy1BjPCKC5E_"
      },
      "outputs": [],
      "source": [
        "def truthful_eval_Mistral (mdl, system_spec_3choice, system_spec_2choice):\n",
        "  # Define a list of column names\n",
        "  columns = [\"case\", \"3-choice\", \"explanation_3\", \"2-choice\", \"explanation_2\"]\n",
        "\n",
        "  # Create an empty DataFrame\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  for case_num in truthful_texts: # iterates through dictionary and finds case number for each truthful case\n",
        "\n",
        "    #Goes through Pandas dataframe to find case facts for that specific case\n",
        "    filtered_df = find_row_by_case_number(truthful, int(case_num))\n",
        "    facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "    text = truthful_texts[case_num]\n",
        "    prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "    three_verdict, explanation_3 = use_mistral(mdl, prompt, system_spec_3choice) # true, false, or indeterminate\n",
        "    two_verdict, explanation_2 = use_mistral(mdl, prompt, system_spec_2choice) # true or false\n",
        "    df = df.append({\n",
        "      \"case\": int(case_num),\n",
        "      \"3-choice\": three_verdict,\n",
        "      \"explanation_3\": explanation_3,\n",
        "      \"2-choice\": two_verdict,\n",
        "      \"explanation_2\": explanation_2,\n",
        "    }, ignore_index=True)\n",
        "  df = df.sort_values(by='case', ascending=True)\n",
        "  df.to_excel(r'/content/drive/MyDrive/Model_Evals/Mistral_Large/truthful.xlsx', index=False) #Need to switch to Mistral_Large when test other model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hOPBwsxEr2X"
      },
      "outputs": [],
      "source": [
        "def deceptive_eval_Mistral (mdl, system_spec_3choice, system_spec_2choice):\n",
        "  # Define a list of column names\n",
        "  columns = [\"case\", \"3-choice\", \"explanation_3\", \"2-choice\", \"explanation_2\"]\n",
        "\n",
        "  # Create an empty DataFrame\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  for case_num in deceptive_texts: # iterates through dictionary and finds case number for each deceptive case\n",
        "\n",
        "    #Goes through Pandas dataframe to find case facts for that specific case\n",
        "    filtered_df = find_row_by_case_number(deceptive, int(case_num))\n",
        "    facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "    text = deceptive_texts[case_num]\n",
        "    prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "    three_verdict, explanation_3 = use_mistral(mdl, prompt, system_spec_3choice) # true, false, or indeterminate\n",
        "    two_verdict, explanation_2 = use_mistral(mdl, prompt, system_spec_2choice) # true or false\n",
        "    df = df.append({\n",
        "      \"case\": int(case_num),\n",
        "      \"3-choice\": three_verdict,\n",
        "      \"explanation_3\": explanation_3,\n",
        "      \"2-choice\": two_verdict,\n",
        "      \"explanation_2\": explanation_2,\n",
        "    }, ignore_index=True)\n",
        "  df = df.sort_values(by='case', ascending=True)\n",
        "  df.to_excel(r'/content/drive/MyDrive/Model_Evals/Mistral_Large/deceptive.xlsx', index=False) #Need to switch to Mistral_Large when test other model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efxoUil7U8lf"
      },
      "outputs": [],
      "source": [
        "def use_mistral(mdl, prompt, system_spec):\n",
        "  messages = [\n",
        "    ChatMessage(role=\"system\", content=system_spec),\n",
        "    ChatMessage(role=\"user\", content=prompt)\n",
        "  ]\n",
        "\n",
        "  chat_response = client.chat(\n",
        "      model=mdl,\n",
        "      messages=messages,\n",
        "      response_format={\"type\": \"json_object\"},\n",
        "      temperature=0.0,\n",
        "  )\n",
        "  print(\"trying json\")\n",
        "  print(chat_response.choices[0].message.content)\n",
        "  json_response = json.loads(chat_response.choices[0].message.content)\n",
        "  print(\"worked\")\n",
        "  return json_response[\"verdict\"], json_response[\"explanation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH0uh22CCO65"
      },
      "outputs": [],
      "source": [
        "system_spec_3choice = '''\n",
        "You are a fact checker for court cases.\n",
        "Based on the case background, determine if an individual’s answers to questions posed by the attorney/judge are truthful (output “Truthful”), deceptive (output “Deceptive”), or if there is not enough information to decide (output “Indeterminate”). An answer is considered deceptive if any part of the answer is not true. Follow these instructions when analyzing the dialogue:\n",
        "\n",
        "1. Do not analyze what is said by the judge/attorney for factuality. Assume they are incapable of lying.\n",
        "\n",
        "2. Only label answers as truthful or deceptive if your decision is explicitly supported by evidence found in the case background. Otherwise, label the answers as “Indeterminate.”\n",
        "\n",
        "3. Format your answer in JSON format as shown below, with your explanation citing evidence extracted from the case background:\n",
        "\n",
        "\t{\n",
        "\n",
        "`\t  “verdict” : Literal [“Truthful”, “Deceptive”, “Indeterminate”],\n",
        "\t  “explanation” : str\n",
        "\n",
        "  }\n",
        "'''\n",
        "\n",
        "system_spec_2choice = '''\n",
        "You are a fact checker for court cases.\n",
        "Based on the case background, determine if an individual’s answers to questions posed by the attorney/judge are truthful (output “Truthful”) or deceptive (output “Deceptive”). An answer is considered deceptive if any part of the answer is not true. Follow these instructions when analyzing the dialogue:\n",
        "\n",
        "1. Do not analyze what is said by the judge/attorney for factuality. Assume they are incapable of lying.\n",
        "\n",
        "2. Format your answer in JSON format as shown below, with your explanation citing evidence extracted from the case background:\n",
        "\n",
        "\t{\n",
        "\n",
        "`\t  “verdict” : Literal [“Truthful”, “Deceptive”]\n",
        "\t  “explanation” : str\n",
        "\n",
        "  }\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'mistral-large-latest'"
      ],
      "metadata": {
        "id": "BIVK-hscWcjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2fYSFlLFpdk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "95b81f88-0510-4ecd-f9d3-bc61d18faca4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MistralAPIException",
          "evalue": "Status: 422. Message: {\"object\":\"error\",\"message\":{\"detail\":[{\"type\":\"extra_forbidden\",\"loc\":[\"body\",\"response_format\"],\"msg\":\"Extra inputs are not permitted\",\"input\":{\"type\":\"json_object\"},\"url\":\"https://errors.pydantic.dev/2.5/v/extra_forbidden\"}]},\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMistralAPIException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-13fa113ea044>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model: open-mixtral-8x7b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model: mistral-large-latest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtruthful_eval_Mistral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_spec_3choice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_spec_2choice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-c415ba17923f>\u001b[0m in \u001b[0;36mtruthful_eval_Mistral\u001b[0;34m(mdl, system_spec_3choice, system_spec_2choice)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'''Here is the case background: \\n\\n\"'''\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfacts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'''\"\\n\\n'''\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mthree_verdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplanation_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_mistral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_spec_3choice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# true, false, or indeterminate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtwo_verdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplanation_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_mistral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_spec_2choice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# true or false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     df = df.append({\n",
            "\u001b[0;32m<ipython-input-41-2d002d23edac>\u001b[0m in \u001b[0;36muse_mistral\u001b[0;34m(mdl, prompt, system_spec)\u001b[0m\n\u001b[1;32m      5\u001b[0m   ]\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   chat_response = client.chat(\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mistralai/client.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, messages, model, tools, temperature, max_tokens, top_p, random_seed, safe_mode, safe_prompt, tool_choice, response_format)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0msingle_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"v1/chat/completions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msingle_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mChatCompletionResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mistralai/client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, json, path, stream, attempt)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 )\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mConnectError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mistralai/client.py\u001b[0m in \u001b[0;36m_check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_response_status_codes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mjson_response\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mistralai/client.py\u001b[0m in \u001b[0;36m_check_response_status_codes\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             raise MistralAPIException.from_response(\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Status: {response.status_code}. Message: {response.text}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMistralAPIException\u001b[0m: Status: 422. Message: {\"object\":\"error\",\"message\":{\"detail\":[{\"type\":\"extra_forbidden\",\"loc\":[\"body\",\"response_format\"],\"msg\":\"Extra inputs are not permitted\",\"input\":{\"type\":\"json_object\"},\"url\":\"https://errors.pydantic.dev/2.5/v/extra_forbidden\"}]},\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}"
          ]
        }
      ],
      "source": [
        "#model: open-mixtral-8x7b\n",
        "#model: mistral-large-latest\n",
        "truthful_eval_Mistral(model, system_spec_3choice, system_spec_2choice)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deceptive_eval_Mistral(model, system_spec_3choice, system_spec_2choice)"
      ],
      "metadata": {
        "id": "FrSqAPYmYccv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMyPPa-7XxD0",
        "outputId": "bf536c3a-adf6-4dfa-c625-3dcd7838fefc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"verdict\": \"Deceptive\", \"explanation\": \"According to the case background, Jonathan Kendrick did perform field service with Candace Conti alone on multiple occasions. Conti testified that the molestations occurred while they were supposed to be performing field service, and they did field service together many times without either of Conti's parents present. Therefore, Kendrick's statement that he has never been alone with Candace Conti is deceptive.\"}\n"
          ]
        }
      ],
      "source": [
        "model = \"mistral-large-latest\"\n",
        "case_num = \"060\"\n",
        "filtered_df = find_row_by_case_number(deceptive, int(case_num))\n",
        "facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "\n",
        "text = deceptive_texts[case_num]\n",
        "prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "response = use_mistral(model, prompt) # for mdl, we will use gpt-4-0125-preview and gpt-3.5-turbo-0125\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxhNW_Bns6Jz",
        "outputId": "0971b0d5-9951-4998-cc16-86e18a9c1ba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deceptive\n"
          ]
        }
      ],
      "source": [
        "print(json.loads(response)[\"verdict\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gGatjTPkbNU"
      },
      "source": [
        "#Claude (Biggest model, Opus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N2Qbvb4lrLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c703c7dc-dbec-4023-98ff-b8f57f64bab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.21.3-py3-none-any.whl (851 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/851.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/851.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m849.9/851.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m851.6/851.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.16.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Installing collected packages: anthropic\n",
            "Successfully installed anthropic-0.21.3\n"
          ]
        }
      ],
      "source": [
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHwyXCeVl8VV"
      },
      "outputs": [],
      "source": [
        "from anthropic import Anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nndxM8vYH5zt"
      },
      "outputs": [],
      "source": [
        "def truthful_eval_Claude (mdl, system_spec_3choice, system_spec_2choice):\n",
        "  # Define a list of column names\n",
        "  columns = [\"case\", \"3-choice\", \"explanation_3\", \"2-choice\", \"explanation_2\"]\n",
        "\n",
        "  # Create an empty DataFrame\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  for case_num in truthful_texts: # iterates through dictionary and finds case number for each truthful case\n",
        "\n",
        "    #Goes through Pandas dataframe to find case facts for that specific case\n",
        "    filtered_df = find_row_by_case_number(truthful, int(case_num))\n",
        "    facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "    text = truthful_texts[case_num]\n",
        "    prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "    three_verdict, explanation_3 = run_anthropic(mdl, prompt, system_spec_3choice) # true, false, or indeterminate\n",
        "    two_verdict, explanation_2 = run_anthropic(mdl, prompt, system_spec_2choice) # true or false\n",
        "    df = df.append({\n",
        "      \"case\": int(case_num),\n",
        "      \"3-choice\": three_verdict,\n",
        "      \"explanation_3\": explanation_3,\n",
        "      \"2-choice\": two_verdict,\n",
        "      \"explanation_2\": explanation_2,\n",
        "    }, ignore_index=True)\n",
        "  df = df.sort_values(by='case', ascending=True)\n",
        "  df.to_excel(r'/content/drive/MyDrive/Model_Evals/Claude_Opus/truthful.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTkE_9Z7IxK-"
      },
      "outputs": [],
      "source": [
        "def deceptive_eval_Claude (mdl, system_spec_3choice, system_spec_2choice):\n",
        "  # Define a list of column names\n",
        "  columns = [\"case\", \"3-choice\", \"explanation_3\", \"2-choice\", \"explanation_2\"]\n",
        "\n",
        "  # Create an empty DataFrame\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  for case_num in deceptive_texts: # iterates through dictionary and finds case number for each deceptive case\n",
        "\n",
        "    #Goes through Pandas dataframe to find case facts for that specific case\n",
        "    filtered_df = find_row_by_case_number(deceptive, int(case_num))\n",
        "    facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "    text = deceptive_texts[case_num]\n",
        "    prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "    three_verdict, explanation_3 = run_anthropic(mdl, prompt, system_spec_3choice) # true, false, or indeterminate\n",
        "    two_verdict, explanation_2 = run_anthropic(mdl, prompt, system_spec_2choice) # true or false\n",
        "    df = df.append({\n",
        "      \"case\": int(case_num),\n",
        "      \"3-choice\": three_verdict,\n",
        "      \"explanation_3\": explanation_3,\n",
        "      \"2-choice\": two_verdict,\n",
        "      \"explanation_2\": explanation_2,\n",
        "    }, ignore_index=True)\n",
        "  df = df.sort_values(by='case', ascending=True)\n",
        "  df.to_excel(r'/content/drive/MyDrive/Model_Evals/Claude_Opus/deceptive.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILOu30IoHMXI"
      },
      "outputs": [],
      "source": [
        "system_spec_3choice = '''\n",
        "You are a fact checkers for court cases.\n",
        "Based on the case background, determine if an individual’s answers to questions posed by the attorney/judge are truthful (output “Truthful”), deceptive (output “Deceptive”), or if there is not enough information to decide (output “Indeterminate”). An answer is considered deceptive if any part of the answer is not true. Follow these instructions when analyzing the dialogue:\n",
        "\n",
        "1. Do not analyze what is said by the judge/attorney for factuality. Assume they are incapable of lying.\n",
        "\n",
        "2. Only label answers as truthful or deceptive if your decision is explicitly supported by evidence found in the case background. Otherwise, label the answers as “Indeterminate.”\n",
        "\n",
        "3. Format your answer in JSON format as shown below, with your explanation citing evidence extracted from the case background:\n",
        "\n",
        "\t{\n",
        "\n",
        "`\t  “verdict” : Literal [“Truthful”, “Deceptive”, “Indeterminate”],\n",
        "\t  “explanation” : str\n",
        "\n",
        "  }\n",
        "'''\n",
        "\n",
        "system_spec_2choice = '''\n",
        "You are a fact checkers for court cases.\n",
        "Based on the case background, determine if an individual’s answers to questions posed by the attorney/judge are truthful (output “Truthful”) or deceptive (output “Deceptive”). An answer is considered deceptive if any part of the answer is not true. Follow these instructions when analyzing the dialogue:\n",
        "\n",
        "1. Do not analyze what is said by the judge/attorney for factuality. Assume they are incapable of lying.\n",
        "\n",
        "2. Format your answer in JSON format as shown below, with your explanation citing evidence extracted from the case background:\n",
        "\n",
        "\t{\n",
        "\n",
        "`\t  “verdict” : Literal [“Truthful”, “Deceptive”],\n",
        "\t  “explanation” : str\n",
        "\n",
        "  }\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxS7ajUeltAJ"
      },
      "outputs": [],
      "source": [
        "def run_anthropic(mdl, prompt, system_spec):\n",
        "  client = Anthropic(\n",
        "      # This is the default and can be omitted\n",
        "      api_key='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',\n",
        "  )\n",
        "\n",
        "  message = client.messages.create(\n",
        "      system=system_spec,\n",
        "      temperature=0.0,\n",
        "      max_tokens=1024, # way more than needed, but it was standard used. Don't want CLS token to be given to model before it puts the closing JSON brackets, so ideally never want it to reach this max\n",
        "      messages=[\n",
        "          { \"role\": \"user\", \"content\": prompt,},\n",
        "          { \"role\": \"assistant\", \"content\": '''{\"verdict\":''',}, #Uitlization of Pre-filled prompt to force it to output in JSON Format\n",
        "          #pre filled prompt cannot end in space\n",
        "      ],\n",
        "      model=mdl,\n",
        "  )\n",
        "  try:\n",
        "    json_response = json.loads('''{\"verdict\":''' + message.content[0].text)\n",
        "    return json_response[\"verdict\"], json_response[\"explanation\"]\n",
        "  except Exception:  # Catches all potential exceptions\n",
        "    return \"Idk\", message.content[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_cbyf2GTT6N"
      },
      "outputs": [],
      "source": [
        "model = 'claude-3-opus-20240229'\n",
        "truthful_eval_Claude(model, system_spec_3choice, system_spec_2choice)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deceptive_eval_Claude(model, system_spec_3choice, system_spec_2choice)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGWkBdN4qhWr",
        "outputId": "26e95086-6385-4ec9-933b-cfe4543cc122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n",
            "<ipython-input-47-bc55d714f3b3>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ReaJBDPleO3",
        "outputId": "9c7f785b-6563-497b-b591-9b901a13765f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ContentBlock(text='  \"Deceptive\",\\n\"explanation\": \"Based on the case background, Jonathan Kendrick\\'s statements that he was never alone with Candace Conti and never molested her are deceptive. The case facts state that Kendrick began molesting Conti when she was around 9 years old and continued until she was 10 or 11. Most of the molestations occurred at Kendrick\\'s home, where he drove Conti after meetings and during field service when they were alone together. Conti testified that \\'there were times when our groups would separate even further... And sometimes he would take me ․ to go do some of these things and then we would end up at his house.\\' So Kendrick\\'s claims of never being alone with Conti or molesting her are directly contradicted by the victim\\'s testimony and the details of the abuse described in the case background.\"}', type='text')]\n"
          ]
        }
      ],
      "source": [
        "model = \"claude-3-opus-20240229\"\n",
        "case_num = \"060\"\n",
        "filtered_df = find_row_by_case_number(deceptive, int(case_num))\n",
        "facts = case_facts[filtered_df['Case Name'].values[0]]\n",
        "\n",
        "\n",
        "text = deceptive_texts[case_num]\n",
        "prompt = '''Here is the case background: \\n\\n\"''' + facts + '''\"\\n\\n''' + text\n",
        "\n",
        "response = run_anthropic(model, prompt) # for mdl, we will use gpt-4-0125-preview and gpt-3.5-turbo-0125\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpHlbmALxGRl",
        "outputId": "e6678d84-3342-4370-9f9e-a01cd6b4d047"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \"Deceptive\",\n",
            "\"explanation\": \"Based on the case background, Jonathan Kendrick's statements that he was never alone with Candace Conti and never molested her are deceptive. The case facts state that Kendrick began molesting Conti when she was around 9 years old and continued until she was 10 or 11. Most of the molestations occurred at Kendrick's home, where he drove Conti after meetings and during field service when they were alone together. Conti testified that 'there were times when our groups would separate even further... And sometimes he would take me ․ to go do some of these things and then we would end up at his house.' So Kendrick's claims of never being alone with Conti or molesting her are directly contradicted by the victim's testimony and the details of the abuse described in the case background.\"}\n"
          ]
        }
      ],
      "source": [
        "print(response[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "JQTPEaJzw8fD",
        "outputId": "b4845f18-23f4-471e-93ca-e0976e19e90a"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'text'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-53ef285322ab>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'''{\"verdict\":'''\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"explanation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
          ]
        }
      ],
      "source": [
        "response = '''{\"verdict\":''' + response[0].text\n",
        "print(json.loads(response)[\"explanation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptr02RLoxaai",
        "outputId": "fb723016-afd9-4ce1-8c39-c0939bd42729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the case background, Jonathan Kendrick's statements that he was never alone with Candace Conti and never molested her are deceptive. The case facts state that Kendrick began molesting Conti when she was around 9 years old and continued until she was 10 or 11. Most of the molestations occurred at Kendrick's home, where he drove Conti after meetings and during field service when they were alone together. Conti testified that 'there were times when our groups would separate even further... And sometimes he would take me ․ to go do some of these things and then we would end up at his house.' So Kendrick's claims of never being alone with Conti or molesting her are directly contradicted by the victim's testimony and the details of the abuse described in the case background.\n"
          ]
        }
      ],
      "source": [
        "print(json.loads(response)[\"explanation\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analyzing Model Outputs and creating final evaluations for each model"
      ],
      "metadata": {
        "id": "WNcUs-hOZTiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_model_output(parent_dir):\n",
        "\n",
        "  #setting up paths\n",
        "  truthful_path = os.path.join(parent_dir, \"truthful.xlsx\")\n",
        "  deceptive_path = os.path.join(parent_dir, \"deceptive.xlsx\")\n",
        "  output_path = os.path.join(parent_dir, \"model_eval.xlsx\")\n",
        "\n",
        "  # Step 1: Read the Excel file\n",
        "  df_truthful = pd.read_excel(truthful_path)\n",
        "  df_deceptive = pd.read_excel(deceptive_path)\n",
        "\n",
        "  # Step 2: Initialize counters (for 3-choice)\n",
        "  correct_truthful = incorrect_truthful = 0 # correct truthful (labeled truth in truth batch) incorrect truthful (labeled truth in deceptive batch)\n",
        "  correct_deceptive = incorrect_deceptive = 0 # correct deceptive (labeled deceptive in deceptive batch) incorrect deceptive (labeled deceptive in truth batch)\n",
        "  truthful_to_indeterminate = deceptive_to_indeterminate = 0 # truthful_to_indeterminate (answer was truth) deceptive_to_indeterminate (answer was deceptive)\n",
        "\n",
        "  # for 2-choice\n",
        "  final_correct_truthful = final_incorrect_truthful = 0 # correct truthful (labeled truth in truth batch) incorrect truthful (labeled truth in deceptive batch)\n",
        "  final_correct_deceptive = final_incorrect_deceptive = 0 # correct deceptive (labeled deceptive in deceptive batch) incorrect deceptive (labeled deceptive in truth batch)\n",
        "\n",
        "  # Step 3: Iterate through truthful rows\n",
        "  for index, row in df_truthful.iterrows():\n",
        "      #dealing with second model prompting ()\n",
        "      if row['3-choice'] == 'Truthful':\n",
        "          correct_truthful += 1\n",
        "\n",
        "      elif row['3-choice'] == \"Deceptive\":\n",
        "            incorrect_deceptive += 1\n",
        "\n",
        "      elif row['3-choice'] == \"Indeterminate\":\n",
        "          truthful_to_indeterminate += 1\n",
        "      else:\n",
        "        print(\"error\")\n",
        "        exit()\n",
        "\n",
        "      if row['2-choice'] == 'Truthful':\n",
        "          final_correct_truthful += 1\n",
        "\n",
        "      elif row['2-choice'] == \"Deceptive\":\n",
        "          final_incorrect_deceptive += 1\n",
        "\n",
        "      else:\n",
        "        print(\"truthful error\")\n",
        "        exit()\n",
        "\n",
        "  # Step 4: Iterate through deceptive rows\n",
        "  for index, row in df_deceptive.iterrows():\n",
        "      #dealing with first model prompting ()\n",
        "      if row['3-choice'] == 'Deceptive':\n",
        "          correct_deceptive += 1\n",
        "\n",
        "      elif row['3-choice'] == \"Truthful\":\n",
        "            incorrect_truthful += 1\n",
        "\n",
        "      elif row['3-choice'] == \"Indeterminate\":\n",
        "          deceptive_to_indeterminate += 1\n",
        "      else:\n",
        "        print(\"error\")\n",
        "        exit()\n",
        "\n",
        "      #dealing with second model prompting ()\n",
        "      if row['2-choice'] == 'Deceptive':\n",
        "          final_correct_deceptive += 1\n",
        "\n",
        "      elif row['2-choice'] == \"Truthful\":\n",
        "          final_incorrect_truthful += 1\n",
        "\n",
        "      else:\n",
        "        print(\"deceptive error\")\n",
        "        print()\n",
        "        exit()\n",
        "\n",
        "\n",
        "  #calulating accuracy\n",
        "\n",
        "  #3 choice\n",
        "  total = correct_truthful + correct_deceptive + incorrect_truthful + incorrect_deceptive + truthful_to_indeterminate + deceptive_to_indeterminate\n",
        "  #accuracy_IndRight = round((total - (incorrect_truthful + incorrect_deceptive)) / (total), 2) #Indeterminate is considered right\n",
        "  accuracy_Ind_irrelevant = round((total - (incorrect_truthful + incorrect_deceptive\n",
        "                                            + truthful_to_indeterminate + deceptive_to_indeterminate)) /\n",
        "                                             (total- (truthful_to_indeterminate + deceptive_to_indeterminate)), 2) #Indeterminate is not considered\n",
        "\n",
        "  precision_TRUTH_3choice = round(correct_truthful / (correct_truthful + incorrect_truthful), 2)\n",
        "  #precision_DECEPTIVE_3choice = round(correct_deceptive / (correct_deceptive + incorrect_deceptive), 2)\n",
        "  recall_TRUTH_3choice = round(correct_truthful / (correct_truthful + incorrect_deceptive), 2)\n",
        "  percent_Ind = round((truthful_to_indeterminate + deceptive_to_indeterminate) / (total), 2) * 100\n",
        "\n",
        "  f1_score_3choice = round((2 * (precision_TRUTH_3choice * recall_TRUTH_3choice)) / (precision_TRUTH_3choice + recall_TRUTH_3choice),2)\n",
        "\n",
        "  #2 choice\n",
        "  total = final_correct_truthful + final_correct_deceptive + final_incorrect_truthful + final_incorrect_deceptive\n",
        "  accuracy = round((final_correct_truthful + final_correct_deceptive) / (total), 2)\n",
        "  precision = round(final_correct_truthful / (final_correct_truthful + final_incorrect_truthful), 2)\n",
        "  recall = round(final_correct_truthful / (final_correct_truthful + final_incorrect_deceptive), 2)\n",
        "\n",
        "  f1_score = round((2 * (precision * recall)) / (precision + recall),2)\n",
        "\n",
        "  # Step 4: Prepare the Results DataFrame\n",
        "  results_df = pd.DataFrame({\n",
        "      \"Label\": [\n",
        "          \"Correct Truthful label\",\n",
        "          \"Incorrect Truthful label\",\n",
        "          \"Correct Deceptive label\",\n",
        "          \"Incorrect Deceptive label\",\n",
        "          \"Indeterminate (correct label truthful)\",\n",
        "          \"Indeterminate (correct label deceptive)\",\n",
        "          \"Accuracy\",\n",
        "          \"Precision\", #based on truth as the positive class\n",
        "          \"Recall\", # based on truth as the positive class\n",
        "          \"F1-score\",\n",
        "          \"% Indeterminate\"\n",
        "      ],\n",
        "      \"3-choice\": [\n",
        "          correct_truthful,\n",
        "          incorrect_truthful,\n",
        "          correct_deceptive,\n",
        "          incorrect_deceptive,\n",
        "          truthful_to_indeterminate,\n",
        "          deceptive_to_indeterminate,\n",
        "          accuracy_Ind_irrelevant,\n",
        "          precision_TRUTH_3choice,\n",
        "          recall_TRUTH_3choice,\n",
        "          f1_score_3choice,\n",
        "          percent_Ind\n",
        "\n",
        "      ],\n",
        "      \"2-choice\": [\n",
        "          final_correct_truthful,\n",
        "          final_incorrect_truthful,\n",
        "          final_correct_deceptive,\n",
        "          final_incorrect_deceptive,\n",
        "          \" - \",\n",
        "          \" - \",\n",
        "          accuracy,\n",
        "          precision,\n",
        "          recall,\n",
        "          f1_score,\n",
        "          \" - \"\n",
        "\n",
        "\n",
        "\n",
        "      ]\n",
        "  })\n",
        "  print(results_df)\n",
        "  # Step 5: Write to Excel File\n",
        "  output_path = os.path.join(parent_dir, \"This_Model_Eval.xlsx\")\n",
        "  print(output_path)\n",
        "  results_df.to_excel(output_path, index=False)"
      ],
      "metadata": {
        "id": "PHNOgUlrZXir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#analyze_model_output(r\"/content/drive/MyDrive/Model_Evals/Llama_V2_70B_Chat\")"
      ],
      "metadata": {
        "id": "eeYtd0sgXYB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_model_output_LLAMa(parent_dir):\n",
        "\n",
        "  #setting up paths\n",
        "  truthful_path = os.path.join(parent_dir, \"truthful.xlsx\")\n",
        "  deceptive_path = os.path.join(parent_dir, \"deceptive.xlsx\")\n",
        "  output_path = os.path.join(parent_dir, \"model_eval.xlsx\")\n",
        "\n",
        "  # Step 1: Read the Excel file\n",
        "  df_truthful = pd.read_excel(truthful_path)\n",
        "  df_deceptive = pd.read_excel(deceptive_path)\n",
        "\n",
        "  # Step 2: Initialize counters (for 3-choice)\n",
        "  correct_truthful = incorrect_truthful = 0 # correct truthful (labeled truth in truth batch) incorrect truthful (labeled truth in deceptive batch)\n",
        "  correct_deceptive = incorrect_deceptive = 0 # correct deceptive (labeled deceptive in deceptive batch) incorrect deceptive (labeled deceptive in truth batch)\n",
        "  truthful_to_indeterminate = deceptive_to_indeterminate = 0 # truthful_to_indeterminate (answer was truth) deceptive_to_indeterminate (answer was deceptive)\n",
        "\n",
        "  # for 2-choice\n",
        "  final_correct_truthful = final_incorrect_truthful = 0 # correct truthful (labeled truth in truth batch) incorrect truthful (labeled truth in deceptive batch)\n",
        "  final_correct_deceptive = final_incorrect_deceptive = 0 # correct deceptive (labeled deceptive in deceptive batch) incorrect deceptive (labeled deceptive in truth batch)\n",
        "\n",
        "  # Step 3: Iterate through truthful rows\n",
        "  for index, row in df_truthful.iterrows():\n",
        "      #dealing with second model prompting ()\n",
        "      if row['3-choice'] == 'Truthful':\n",
        "          correct_truthful += 1\n",
        "\n",
        "      elif row['3-choice'] == \"Deceptive\":\n",
        "            incorrect_deceptive += 1\n",
        "\n",
        "      elif row['3-choice'] == \"Indeterminate\":\n",
        "          truthful_to_indeterminate += 1\n",
        "      else:\n",
        "        print(\"error\")\n",
        "        exit()\n",
        "\n",
        "      if row['2-choice'] == 'Truthful':\n",
        "          final_correct_truthful += 1\n",
        "\n",
        "      elif row['2-choice'] == \"Deceptive\":\n",
        "          final_incorrect_deceptive += 1\n",
        "\n",
        "      else:\n",
        "        print(row['2-choice'])\n",
        "        exit()\n",
        "\n",
        "  # Step 4: Iterate through deceptive rows\n",
        "  for index, row in df_deceptive.iterrows():\n",
        "      #dealing with first model prompting ()\n",
        "      if row['3-choice'] == 'Deceptive':\n",
        "          correct_deceptive += 1\n",
        "\n",
        "      elif row['3-choice'] == \"Truthful\":\n",
        "            incorrect_truthful += 1\n",
        "\n",
        "      elif row['3-choice'] == \"Indeterminate\":\n",
        "          deceptive_to_indeterminate += 1\n",
        "      else:\n",
        "        print(\"error\")\n",
        "        exit()\n",
        "\n",
        "      #dealing with second model prompting ()\n",
        "      if row['2-choice'] == 'Deceptive':\n",
        "          final_correct_deceptive += 1\n",
        "\n",
        "      elif row['2-choice'] == \"Truthful\":\n",
        "          final_incorrect_truthful += 1\n",
        "\n",
        "      else:\n",
        "        print(row['2-choice'])\n",
        "        exit()\n",
        "\n",
        "\n",
        "  #calulating accuracy\n",
        "\n",
        "  #3 choice\n",
        "  total = correct_truthful + correct_deceptive + incorrect_truthful + incorrect_deceptive + truthful_to_indeterminate + deceptive_to_indeterminate\n",
        "  #accuracy_IndRight = round((total - (incorrect_truthful + incorrect_deceptive)) / (total), 2) #Indeterminate is considered right\n",
        "  accuracy_Ind_irrelevant = round((total - (incorrect_truthful + incorrect_deceptive\n",
        "                                            + truthful_to_indeterminate + deceptive_to_indeterminate)) /\n",
        "                                             (total- (truthful_to_indeterminate + deceptive_to_indeterminate)), 2) #Indeterminate is not considered\n",
        "\n",
        "  precision_TRUTH_3choice = round(correct_truthful / (correct_truthful + incorrect_truthful), 2)\n",
        "  #precision_DECEPTIVE_3choice = round(correct_deceptive / (correct_deceptive + incorrect_deceptive), 2)\n",
        "  recall_TRUTH_3choice = round(correct_truthful / (correct_truthful + incorrect_deceptive), 2)\n",
        "  percent_Ind = round((truthful_to_indeterminate + deceptive_to_indeterminate) / (total), 2) * 100\n",
        "\n",
        "  f1_score_3choice = round((2 * (precision_TRUTH_3choice * recall_TRUTH_3choice)) / (precision_TRUTH_3choice + recall_TRUTH_3choice),2)\n",
        "\n",
        "  #2 choice\n",
        "  total = final_correct_truthful + final_correct_deceptive + final_incorrect_truthful + final_incorrect_deceptive\n",
        "  accuracy = round((final_correct_truthful + final_correct_deceptive) / (total), 2)\n",
        "  precision = round(final_correct_truthful / (final_correct_truthful + final_incorrect_truthful), 2)\n",
        "  recall = round(final_correct_truthful / (final_correct_truthful + final_incorrect_deceptive), 2)\n",
        "\n",
        "  f1_score = round((2 * (precision * recall)) / (precision + recall),2)\n",
        "\n",
        "  # Step 4: Prepare the Results DataFrame\n",
        "  results_df = pd.DataFrame({\n",
        "      \"Label\": [\n",
        "          \"Correct Truthful label\",\n",
        "          \"Incorrect Truthful label\",\n",
        "          \"Correct Deceptive label\",\n",
        "          \"Incorrect Deceptive label\",\n",
        "          \"Indeterminate (correct label truthful)\",\n",
        "          \"Indeterminate (correct label deceptive)\",\n",
        "          \"Accuracy\",\n",
        "          \"Precision\", #based on truth as the positive class\n",
        "          \"Recall\", # based on truth as the positive class\n",
        "          \"F1-score\",\n",
        "          \"% Indeterminate\"\n",
        "      ],\n",
        "      \"3-choice\": [\n",
        "          correct_truthful,\n",
        "          incorrect_truthful,\n",
        "          correct_deceptive,\n",
        "          incorrect_deceptive,\n",
        "          truthful_to_indeterminate,\n",
        "          deceptive_to_indeterminate,\n",
        "          accuracy_Ind_irrelevant,\n",
        "          precision_TRUTH_3choice,\n",
        "          recall_TRUTH_3choice,\n",
        "          f1_score_3choice,\n",
        "          percent_Ind\n",
        "\n",
        "      ],\n",
        "      \"2-choice\": [\n",
        "          final_correct_truthful,\n",
        "          final_incorrect_truthful,\n",
        "          final_correct_deceptive,\n",
        "          final_incorrect_deceptive,\n",
        "          \" - \",\n",
        "          \" - \",\n",
        "          accuracy,\n",
        "          precision,\n",
        "          recall,\n",
        "          f1_score,\n",
        "          \" - \"\n",
        "\n",
        "\n",
        "\n",
        "      ]\n",
        "  })\n",
        "  print(results_df)\n",
        "  # Step 5: Write to Excel File\n",
        "  output_path = os.path.join(parent_dir, \"This_Model_Eval.xlsx\")\n",
        "  print(output_path)\n",
        "  results_df.to_excel(output_path, index=False)"
      ],
      "metadata": {
        "id": "V-Koru9ihvhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_model_output_LLAMa(r\"/content/drive/MyDrive/Model_Evals/Llama_V2_70B_Chat\")"
      ],
      "metadata": {
        "id": "OMXjLR_Yh--J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_model_output_GPT(parent_dir):\n",
        "\n",
        "  #setting up paths\n",
        "  truthful_path = os.path.join(parent_dir, \"truthful.xlsx\")\n",
        "  deceptive_path = os.path.join(parent_dir, \"deceptive.xlsx\")\n",
        "  output_path = os.path.join(parent_dir, \"model_eval.xlsx\")\n",
        "\n",
        "  # Step 1: Read the Excel file\n",
        "  df_truthful = pd.read_excel(truthful_path)\n",
        "  df_deceptive = pd.read_excel(deceptive_path)\n",
        "\n",
        "  # Step 2: Initialize counters (for 3-choice)\n",
        "  correct_truthful = incorrect_truthful = 0 # correct truthful (labeled truth in truth batch) incorrect truthful (labeled truth in deceptive batch)\n",
        "  correct_deceptive = incorrect_deceptive = 0 # correct deceptive (labeled deceptive in deceptive batch) incorrect deceptive (labeled deceptive in truth batch)\n",
        "  truthful_to_indeterminate = deceptive_to_indeterminate = 0 # truthful_to_indeterminate (answer was truth) deceptive_to_indeterminate (answer was deceptive)\n",
        "\n",
        "  # Step 3: Iterate through truthful rows\n",
        "  for index, row in df_truthful.iterrows():\n",
        "      #dealing with second model prompting ()\n",
        "      if row['verdict'] == 'Truthful':\n",
        "          correct_truthful += 1\n",
        "\n",
        "      elif row['verdict'] == \"Deceptive\":\n",
        "            incorrect_deceptive += 1\n",
        "\n",
        "      elif row['verdict'] == \"Indeterminate\":\n",
        "          truthful_to_indeterminate += 1\n",
        "      else:\n",
        "        print(\"error\")\n",
        "        exit()\n",
        "\n",
        "  # Step 4: Iterate through deceptive rows\n",
        "  for index, row in df_deceptive.iterrows():\n",
        "      #dealing with first model prompting ()\n",
        "      if row['verdict'] == 'Deceptive':\n",
        "          correct_deceptive += 1\n",
        "\n",
        "      elif row['verdict'] == \"Truthful\":\n",
        "            incorrect_truthful += 1\n",
        "\n",
        "      elif row['verdict'] == \"Indeterminate\":\n",
        "          deceptive_to_indeterminate += 1\n",
        "      else:\n",
        "        print(\"error\")\n",
        "        exit()\n",
        "\n",
        "  #calulating accuracy\n",
        "\n",
        "  #3 choice\n",
        "  total = correct_truthful + correct_deceptive + incorrect_truthful + incorrect_deceptive + truthful_to_indeterminate + deceptive_to_indeterminate\n",
        "  #accuracy_IndRight = round((total - (incorrect_truthful + incorrect_deceptive)) / (total), 2) #Indeterminate is considered right\n",
        "  accuracy_Ind_irrelevant = round((total - (incorrect_truthful + incorrect_deceptive\n",
        "                                            + truthful_to_indeterminate + deceptive_to_indeterminate)) /\n",
        "                                             (total- (truthful_to_indeterminate + deceptive_to_indeterminate)), 2) #Indeterminate is not considered\n",
        "\n",
        "  precision_TRUTH_3choice = round(correct_truthful / (correct_truthful + incorrect_truthful), 2)\n",
        "  #precision_DECEPTIVE_3choice = round(correct_deceptive / (correct_deceptive + incorrect_deceptive), 2)\n",
        "  recall_TRUTH_3choice = round(correct_truthful / (correct_truthful + incorrect_deceptive), 2)\n",
        "  percent_Ind = round((truthful_to_indeterminate + deceptive_to_indeterminate) / (total), 2) * 100\n",
        "\n",
        "  f1_score_3choice = round((2 * (precision_TRUTH_3choice * recall_TRUTH_3choice)) / (precision_TRUTH_3choice + recall_TRUTH_3choice),2)\n",
        "\n",
        "  # Step 4: Prepare the Results DataFrame\n",
        "  results_df = pd.DataFrame({\n",
        "      \"Label\": [\n",
        "          \"Correct Truthful label\",\n",
        "          \"Incorrect Truthful label\",\n",
        "          \"Correct Deceptive label\",\n",
        "          \"Incorrect Deceptive label\",\n",
        "          \"Indeterminate (correct label truthful)\",\n",
        "          \"Indeterminate (correct label deceptive)\",\n",
        "          \"Accuracy\",\n",
        "          \"Precision\", #based on truth as the positive class\n",
        "          \"Recall\", # based on truth as the positive class\n",
        "          \"F1-score\",\n",
        "          \"% Indeterminate\"\n",
        "      ],\n",
        "      \"3-choice\": [\n",
        "          correct_truthful,\n",
        "          incorrect_truthful,\n",
        "          correct_deceptive,\n",
        "          incorrect_deceptive,\n",
        "          truthful_to_indeterminate,\n",
        "          deceptive_to_indeterminate,\n",
        "          accuracy_Ind_irrelevant,\n",
        "          precision_TRUTH_3choice,\n",
        "          recall_TRUTH_3choice,\n",
        "          f1_score_3choice,\n",
        "          percent_Ind\n",
        "\n",
        "      ]\n",
        "  })\n",
        "  print(results_df)\n",
        "  # Step 5: Write to Excel File\n",
        "  output_path = os.path.join(parent_dir, \"This_Model_Eval_3-Choice.xlsx\")\n",
        "  print(output_path)\n",
        "  results_df.to_excel(output_path, index=False)"
      ],
      "metadata": {
        "id": "mVmmPRl1iquj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_model_output_GPT(r\"/content/drive/MyDrive/Model_Evals/GPT_4_Turbo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi5r_KZOsjMN",
        "outputId": "a68d3c3e-0b75-44c2-d3f1-1c3d615f9912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Label  3-choice\n",
            "0                    Correct Truthful label     12.00\n",
            "1                  Incorrect Truthful label      1.00\n",
            "2                   Correct Deceptive label     17.00\n",
            "3                 Incorrect Deceptive label      4.00\n",
            "4    Indeterminate (correct label truthful)     27.00\n",
            "5   Indeterminate (correct label deceptive)     25.00\n",
            "6                                  Accuracy      0.85\n",
            "7                                 Precision      0.92\n",
            "8                                    Recall      0.75\n",
            "9                                  F1-score      0.83\n",
            "10                          % Indeterminate     60.00\n",
            "/content/drive/MyDrive/Model_Evals/GPT_4_Turbo/This_Model_Eval_3-Choice.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_GPT_2choice(parent_dir):\n",
        "\n",
        "  #setting up paths\n",
        "  truthful_path = os.path.join(parent_dir, \"truthful_2choice.xlsx\")\n",
        "  deceptive_path = os.path.join(parent_dir, \"deceptive_2choice.xlsx\")\n",
        "  output_path = os.path.join(parent_dir, \"model_eval.xlsx\")\n",
        "\n",
        "  # Step 1: Read the Excel file\n",
        "  df_truthful = pd.read_excel(truthful_path)\n",
        "  df_deceptive = pd.read_excel(deceptive_path)\n",
        "\n",
        "  # for 2-choice\n",
        "  final_correct_truthful = final_incorrect_truthful = 0 # correct truthful (labeled truth in truth batch) incorrect truthful (labeled truth in deceptive batch)\n",
        "  final_correct_deceptive = final_incorrect_deceptive = 0 # correct deceptive (labeled deceptive in deceptive batch) incorrect deceptive (labeled deceptive in truth batch)\n",
        "\n",
        "  # Step 3: Iterate through truthful rows\n",
        "  for index, row in df_truthful.iterrows():\n",
        "      if row['verdict'] == 'Truthful':\n",
        "          final_correct_truthful += 1\n",
        "\n",
        "      elif row['verdict'] == \"Deceptive\":\n",
        "          final_incorrect_deceptive += 1\n",
        "\n",
        "      else:\n",
        "        print(\"truthful error\")\n",
        "        exit()\n",
        "\n",
        "  # Step 4: Iterate through deceptive rows\n",
        "  for index, row in df_deceptive.iterrows():\n",
        "      #dealing with second model prompting ()\n",
        "      if row['verdict'] == 'Deceptive':\n",
        "          final_correct_deceptive += 1\n",
        "\n",
        "      elif row['verdict'] == \"Truthful\":\n",
        "          final_incorrect_truthful += 1\n",
        "\n",
        "      else:\n",
        "        print(\"deceptive error\")\n",
        "        print()\n",
        "        exit()\n",
        "\n",
        "\n",
        "  #calulating accuracy\n",
        "  #2 choice\n",
        "  total = final_correct_truthful + final_correct_deceptive + final_incorrect_truthful + final_incorrect_deceptive\n",
        "  accuracy = round((final_correct_truthful + final_correct_deceptive) / (total), 2)\n",
        "  precision = round(final_correct_truthful / (final_correct_truthful + final_incorrect_truthful), 2)\n",
        "  recall = round(final_correct_truthful / (final_correct_truthful + final_incorrect_deceptive), 2)\n",
        "\n",
        "  f1_score = round((2 * (precision * recall)) / (precision + recall),2)\n",
        "\n",
        "  # Step 4: Prepare the Results DataFrame\n",
        "  results_df = pd.DataFrame({\n",
        "      \"Label\": [\n",
        "          \"Correct Truthful label\",\n",
        "          \"Incorrect Truthful label\",\n",
        "          \"Correct Deceptive label\",\n",
        "          \"Incorrect Deceptive label\",\n",
        "          \"Accuracy\",\n",
        "          \"Precision\", #based on truth as the positive class\n",
        "          \"Recall\", # based on truth as the positive class\n",
        "          \"F1-score\",\n",
        "      ],\n",
        "      \"2-choice\": [\n",
        "          final_correct_truthful,\n",
        "          final_incorrect_truthful,\n",
        "          final_correct_deceptive,\n",
        "          final_incorrect_deceptive,\n",
        "          accuracy,\n",
        "          precision,\n",
        "          recall,\n",
        "          f1_score\n",
        "\n",
        "\n",
        "\n",
        "      ]\n",
        "  })\n",
        "  print(results_df)\n",
        "  # Step 5: Write to Excel File\n",
        "  output_path = os.path.join(parent_dir, \"This_Model_Eval_2choice.xlsx\")\n",
        "  print(output_path)\n",
        "  results_df.to_excel(output_path, index=False)"
      ],
      "metadata": {
        "id": "C0afi1g3t4eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_GPT_2choice(r\"/content/drive/MyDrive/Model_Evals/GPT_3.5_Turbo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwvTNTc8vDey",
        "outputId": "408a2bdf-8182-4b73-fc38-a16675cc9fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Label  2-choice\n",
            "0     Correct Truthful label     31.00\n",
            "1   Incorrect Truthful label     11.00\n",
            "2    Correct Deceptive label     32.00\n",
            "3  Incorrect Deceptive label     12.00\n",
            "4                   Accuracy      0.73\n",
            "5                  Precision      0.74\n",
            "6                     Recall      0.72\n",
            "7                   F1-score      0.73\n",
            "/content/drive/MyDrive/Model_Evals/GPT_3.5_Turbo/This_Model_Eval_2choice.xlsx\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}